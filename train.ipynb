{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os \n",
    "EPOCHS = 10\n",
    "ckpt_dir = './ckpts/'\n",
    "batch_size, height, width = 4,128,128\n",
    "in_flows = 20\n",
    "device = 'cuda'\n",
    "starting_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Parameters: 16929120\n"
     ]
    }
   ],
   "source": [
    "from model import MPI_Net\n",
    "model = MPI_Net(input_channels= in_flows*2,num_outputs=in_flows*2, ngf=32).train().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas = [0.9,0.99])\n",
    "ckpts = os.listdir(ckpt_dir)\n",
    "if ckpts:\n",
    "    ckpts = sorted(ckpts, key = lambda x : x.split('.')[0].split('_')[1]) #sort\n",
    "    latest = ckpts[-1]\n",
    "    state_dict = torch.load(os.path.join(ckpt_dir,latest))\n",
    "    model.load_state_dict(state_dict['model'])\n",
    "    starting_epoch = state_dict['epoch'] + 1\n",
    "    optimizer.load_state_dict(state_dict['optimizer'])\n",
    "    print('loaded weights from previous session')\n",
    "    print(f'starting from epoch {starting_epoch}')\n",
    "    print('learning_rate',optimizer.param_groups[0]['lr'])\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Trainable Parameters: {total_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "class DeepStab_Synthetic(Dataset):\n",
    "    def __init__(self, txt_path = './trainlist.txt'):\n",
    "        with open(txt_path, 'r') as f:\n",
    "            self.trainlist = f.read().splitlines()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trainlist)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sample = self.trainlist[idx]\n",
    "        path = sample.split(',')[0]\n",
    "        idx = int(sample.split(',')[1])\n",
    "        flow_file = np.load(path, mmap_mode='r')\n",
    "        sequence = flow_file[idx: idx + in_flows,...]\n",
    "        sequence = np.concatenate(sequence,axis = -1)\n",
    "        seq = torch.from_numpy(sequence).permute(2,0,1).float()\n",
    "        return seq\n",
    "\n",
    "\n",
    "train_ds = DeepStab_Synthetic()\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses\n",
    "def motion_loss(net_out, net_in):\n",
    "    '''\n",
    "    input:\n",
    "        net_out/W: networks output warp fields W torch.Size([1, 160, 128,128])\n",
    "        net_in/F: networks input PCA Filled fields F torch.Size([1, 160, 128,128])\n",
    "    '''\n",
    "    epsilon = 1e-8\n",
    "    device = net_out.device  # Get the device of net_out tensor\n",
    "    b, c, h, w = net_out.shape\n",
    "    dx = net_out[:, ::2, :, :]\n",
    "    dy = net_out[:, 1::2, :, :]\n",
    "    W = torch.stack([dx, dy], dim=-1).to(device)  # Move to the same device\n",
    "    dx = net_in[:, ::2, :, :]\n",
    "    dy = net_in[:, 1::2, :, :]\n",
    "    F = torch.stack([dx, dy], dim=-1).to(device)  # Move to the same device\n",
    "    pixel_trajectories = torch.cumsum(F, dim=1)\n",
    "    smooth_trajectories = pixel_trajectories + W\n",
    "    p_hat = pixel_trajectories[:,:-1, ...] + W[:,:-1, ...]\n",
    "    q_hat = pixel_trajectories[:,1:, ...] + W[:,1:, ...]\n",
    "    smoothness = torch.mean(torch.sum(torch.sqrt(torch.sum(torch.pow(p_hat - q_hat + epsilon, 2), dim=-1)), dim = (1,2,3)))\n",
    "    similarity = torch.mean(torch.sqrt((pixel_trajectories - smooth_trajectories + epsilon)**2))\n",
    "\n",
    "    magnitude = torch.sqrt(dx.mean()**2 + dy.mean()**2)\n",
    "    indicator = max(-1.93 * magnitude + 0.95,0)\n",
    "    return indicator * smoothness + similarity\n",
    "\n",
    "\n",
    "def spatial_loss(net_out):\n",
    "    '''\n",
    "    input:\n",
    "        net_out/W: networks output warp fields W torch.Size([1, 160, 128,128])\n",
    "    '''\n",
    "    epsilon = 1e-8\n",
    "    device = net_out.device  # Get the device of net_out tensor\n",
    "    b, c, h, w = net_out.shape\n",
    "    dx = net_out[:, ::2, :, :]\n",
    "    dy = net_out[:, 1::2, :, :]\n",
    "    W = torch.stack([dx, dy], dim=-1).to(device)  # Move to the same device\n",
    "    W_fft = torch.fft.fft2(W)\n",
    "    # Shift the zero-frequency component to the center of the spectrum\n",
    "    W_fft_shifted = torch.fft.fftshift(W_fft)\n",
    "\n",
    "    magnitude_spectrum = torch.abs(W_fft_shifted)\n",
    "    mu = 0\n",
    "    sigma = 3\n",
    "    x = torch.arange(h)\n",
    "    y = torch.arange(w)\n",
    "    xx, yy = torch.meshgrid(x, y, indexing='ij')\n",
    "    mask = torch.exp(-0.5 * ((xx - mu) ** 2 + (yy - mu) ** 2) / sigma ** 2)\n",
    "    inverted_mask = (mask.max() - mask) / (mask.max() + epsilon)\n",
    "    inverted_mask -= inverted_mask.mean()\n",
    "    inverted_mask = inverted_mask.unsqueeze(0).unsqueeze(1).unsqueeze(-1).repeat(b,in_flows, 1, 1, 2).to(device)  # Move to the same device\n",
    "    magnitude_spectrum = inverted_mask * magnitude_spectrum\n",
    "    magnitude_spectrum.shape\n",
    "    loss = torch.mean(torch.sqrt((magnitude_spectrum + epsilon)**2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_flow(flow):\n",
    "    hsv_mask = np.zeros(shape= flow.shape[:-1] +(3,),dtype = np.uint8)\n",
    "    hsv_mask[...,1] = 255\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1],angleInDegrees=True)\n",
    "    hsv_mask[:,:,0] = ang /2 \n",
    "    hsv_mask[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv_mask,cv2.COLOR_HSV2RGB)\n",
    "    return(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len = len(train_ds.trainlist)\n",
    "cv2.namedWindow('window',cv2.WINDOW_NORMAL)\n",
    "for epoch in range(starting_epoch,EPOCHS):\n",
    "    if epoch > 0 :\n",
    "        for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = 1e-5\n",
    "    running_loss = 0\n",
    "    #for idx,f in enumerate(data_loader):\n",
    "    for idx,f in enumerate(train_loader):\n",
    "        loss = 0\n",
    "        f = f.to('cuda')\n",
    "        w = model(f)\n",
    "        lm = motion_loss(w,f)\n",
    "        loss += lm\n",
    "        if epoch < 1:\n",
    "            lf =  10 * spatial_loss(w)\n",
    "            loss += lf\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pca =  f[0,40:42,:,:].cpu().detach().permute(1,2,0).numpy()\n",
    "        pred = w[0,40:42,:,:].cpu().detach().permute(1,2,0).numpy()\n",
    "        img1 = show_flow(pred)\n",
    "        img2 = show_flow(pca)\n",
    "        conc = cv2.hconcat([img1, img2])\n",
    "\n",
    "        cv2.imshow('window',conc)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('9'):\n",
    "            break    \n",
    "        print(f'\\repoch: {epoch} iter:{idx} loss: {running_loss / (idx % 1000 + 1) :.4f}',end =\"\")\n",
    "        if idx % 1000 == 999:\n",
    "            writer.add_scalar('training_loss',\n",
    "                                running_loss / 1000,\n",
    "                                epoch * dataset_len + idx)\n",
    "            running_loss = 0.0\n",
    "            model_path = os.path.join(ckpt_dir,f'mpi_{epoch}.pth')\n",
    "            torch.save({'model':model.state_dict(),\n",
    "                        'optimizer' : optimizer.state_dict(),\n",
    "                        'epoch' : epoch}\n",
    "                    ,model_path)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DUTCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
